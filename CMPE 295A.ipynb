{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "udata = []\n",
    "with open('ml-100k/u.data', 'r') as f:\n",
    "    reader1 = csv.reader(f)\n",
    "    udata = list(reader1)\n",
    "\n",
    "udataList = []\n",
    "movies = []\n",
    "for i in udata:\n",
    "    udataList.append(i[0].split('\\t'))\n",
    "    if i[0].split('\\t')[1] not in movies:\n",
    "        movies.append(i[0].split('\\t')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "random100Movies1 = np.random.choice(movies, 100, replace=False)\n",
    "random100Movies2 = np.random.choice(movies, 100, replace=False)\n",
    "random100Movies3 = np.random.choice(movies, 100, replace=False)\n",
    "random100Movies4 = np.random.choice(movies, 100, replace=False)\n",
    "random100Movies5 = np.random.choice(movies, 100, replace=False)\n",
    "\n",
    "#print(random100Movies)\n",
    "\n",
    "diction1 = {}\n",
    "diction2 = {}\n",
    "diction3 = {}\n",
    "diction4 = {}\n",
    "diction5 = {}\n",
    "\n",
    "for i in random100Movies1:\n",
    "    diction1.update({i:0})\n",
    "for i in random100Movies2:\n",
    "    diction2.update({i:0})\n",
    "for i in random100Movies3:\n",
    "    diction3.update({i:0})\n",
    "for i in random100Movies4:\n",
    "    diction4.update({i:0})\n",
    "for i in random100Movies5:\n",
    "    diction5.update({i:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test1','w') as test, open('train1','w') as train:\n",
    "    for i in udataList:\n",
    "        if i[1] not in random100Movies1:\n",
    "            train.write(str(i[0])+\"\\t\"+str(i[1])+\"\\t\"+str(i[2])+\"\\n\")\n",
    "        elif i[1] in random100Movies1 and diction1[i[1]] <= 1:\n",
    "            train.write(str(i[0])+\"\\t\"+str(i[1])+\"\\t\"+str(i[2])+\"\\n\")\n",
    "            diction1[i[1]] += 1\n",
    "        else:\n",
    "            test.write(str(i[0])+\",\"+str(i[1])+\",\"+str(i[2])+\"\\n\")\n",
    "\n",
    "with open('test2','w') as test, open('train2','w') as train:\n",
    "    for i in udataList:\n",
    "        if i[1] not in random100Movies2:\n",
    "            train.write(str(i[0])+\"\\t\"+str(i[1])+\"\\t\"+str(i[2])+\"\\n\")\n",
    "        elif i[1] in random100Movies2 and diction2[i[1]] <= 3:\n",
    "            train.write(str(i[0])+\"\\t\"+str(i[1])+\"\\t\"+str(i[2])+\"\\n\")\n",
    "            diction2[i[1]] += 1\n",
    "        else:\n",
    "            test.write(str(i[0])+\",\"+str(i[1])+\",\"+str(i[2])+\"\\n\")\n",
    "            \n",
    "with open('test3','w') as test, open('train3','w') as train:\n",
    "    for i in udataList:\n",
    "        if i[1] not in random100Movies3:\n",
    "            train.write(str(i[0])+\"\\t\"+str(i[1])+\"\\t\"+str(i[2])+\"\\n\")\n",
    "        elif i[1] in random100Movies3 and diction3[i[1]] <= 5:\n",
    "            train.write(str(i[0])+\"\\t\"+str(i[1])+\"\\t\"+str(i[2])+\"\\n\")\n",
    "            diction3[i[1]] += 1\n",
    "        else:\n",
    "            test.write(str(i[0])+\",\"+str(i[1])+\",\"+str(i[2])+\"\\n\")\n",
    "            \n",
    "with open('test4','w') as test, open('train4','w') as train:\n",
    "    for i in udataList:\n",
    "        if i[1] not in random100Movies4:\n",
    "            train.write(str(i[0])+\"\\t\"+str(i[1])+\"\\t\"+str(i[2])+\"\\n\")\n",
    "        elif i[1] in random100Movies4 and diction4[i[1]] <= 7:\n",
    "            train.write(str(i[0])+\"\\t\"+str(i[1])+\"\\t\"+str(i[2])+\"\\n\")\n",
    "            diction4[i[1]] += 1\n",
    "        else:\n",
    "            test.write(str(i[0])+\",\"+str(i[1])+\",\"+str(i[2])+\"\\n\")\n",
    "            \n",
    "with open('test5','w') as test, open('train5','w') as train:\n",
    "    for i in udataList:\n",
    "        if i[1] not in random100Movies5:\n",
    "            train.write(str(i[0])+\"\\t\"+str(i[1])+\"\\t\"+str(i[2])+\"\\n\")\n",
    "        elif i[1] in random100Movies5 and diction5[i[1]] <= 9:\n",
    "            train.write(str(i[0])+\"\\t\"+str(i[1])+\"\\t\"+str(i[2])+\"\\n\")\n",
    "            diction5[i[1]] += 1\n",
    "        else:\n",
    "            test.write(str(i[0])+\",\"+str(i[1])+\",\"+str(i[2])+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "import os\n",
    "\n",
    "file_path1 = os.path.expanduser('train1')\n",
    "file_path2 = os.path.expanduser('train2')\n",
    "file_path3 = os.path.expanduser('train3')\n",
    "file_path4 = os.path.expanduser('train4')\n",
    "file_path5 = os.path.expanduser('train5')\n",
    "\n",
    "reader = Reader(line_format='user item rating', sep='\\t')\n",
    "\n",
    "traindata1 = Dataset.load_from_file(file_path1, reader=reader)\n",
    "traindata2 = Dataset.load_from_file(file_path2, reader=reader)\n",
    "traindata3 = Dataset.load_from_file(file_path3, reader=reader)\n",
    "traindata4 = Dataset.load_from_file(file_path4, reader=reader)\n",
    "traindata5 = Dataset.load_from_file(file_path5, reader=reader)\n",
    "\n",
    "with open('test1', 'r') as f:\n",
    "    reader1 = csv.reader(f)\n",
    "    data = list(reader1)\n",
    "li = []\n",
    "for line in range(1, len(data)):\n",
    "    li.append(tuple(data[line]))\n",
    "\n",
    "testset1 = []\n",
    "for i in li:\n",
    "    testset1.append(tuple([i[0],i[1],int(i[2])]))\n",
    "#-----\n",
    "with open('test2', 'r') as f:\n",
    "    reader1 = csv.reader(f)\n",
    "    data = list(reader1)\n",
    "li = []\n",
    "for line in range(1, len(data)):\n",
    "    li.append(tuple(data[line]))\n",
    "\n",
    "testset2 = []\n",
    "for i in li:\n",
    "    testset2.append(tuple([i[0],i[1],int(i[2])]))\n",
    "#-----\n",
    "with open('test3', 'r') as f:\n",
    "    reader1 = csv.reader(f)\n",
    "    data = list(reader1)\n",
    "li = []\n",
    "for line in range(1, len(data)):\n",
    "    li.append(tuple(data[line]))\n",
    "\n",
    "testset3 = []\n",
    "for i in li:\n",
    "    testset3.append(tuple([i[0],i[1],int(i[2])]))\n",
    "#-----\n",
    "with open('test4', 'r') as f:\n",
    "    reader1 = csv.reader(f)\n",
    "    data = list(reader1)\n",
    "li = []\n",
    "for line in range(1, len(data)):\n",
    "    li.append(tuple(data[line]))\n",
    "\n",
    "testset4 = []\n",
    "for i in li:\n",
    "    testset4.append(tuple([i[0],i[1],int(i[2])]))\n",
    "#-----\n",
    "with open('test5', 'r') as f:\n",
    "    reader1 = csv.reader(f)\n",
    "    data = list(reader1)\n",
    "li = []\n",
    "for line in range(1, len(data)):\n",
    "    li.append(tuple(data[line]))\n",
    "\n",
    "testset5 = []\n",
    "for i in li:\n",
    "    testset5.append(tuple([i[0],i[1],int(i[2])]))\n",
    "#-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0388\n",
      "MAE:  0.8397\n",
      "RMSE: 0.9973\n",
      "MAE:  0.8080\n",
      "RMSE: 0.9955\n",
      "MAE:  0.8021\n",
      "RMSE: 0.9764\n",
      "MAE:  0.7815\n",
      "RMSE: 0.9658\n",
      "MAE:  0.7715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7714644712664473"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD, accuracy\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "trainset1 = traindata1.build_full_trainset()\n",
    "algo.fit(trainset1)\n",
    "\n",
    "predictions = algo.test(testset1)\n",
    "accuracy.rmse(predictions, verbose=True)\n",
    "accuracy.mae(predictions, verbose=True)\n",
    "#-----\n",
    "trainset2 = traindata2.build_full_trainset()\n",
    "algo.fit(trainset2)\n",
    "\n",
    "predictions = algo.test(testset2)\n",
    "accuracy.rmse(predictions, verbose=True)\n",
    "accuracy.mae(predictions, verbose=True)\n",
    "#-----\n",
    "trainset3 = traindata3.build_full_trainset()\n",
    "algo.fit(trainset3)\n",
    "\n",
    "predictions = algo.test(testset3)\n",
    "accuracy.rmse(predictions, verbose=True)\n",
    "accuracy.mae(predictions, verbose=True)\n",
    "#-----\n",
    "trainset4 = traindata4.build_full_trainset()\n",
    "algo.fit(trainset4)\n",
    "\n",
    "predictions = algo.test(testset4)\n",
    "accuracy.rmse(predictions, verbose=True)\n",
    "accuracy.mae(predictions, verbose=True)\n",
    "#-----\n",
    "trainset5 = traindata5.build_full_trainset()\n",
    "algo.fit(trainset5)\n",
    "\n",
    "predictions = algo.test(testset5)\n",
    "accuracy.rmse(predictions, verbose=True)\n",
    "accuracy.mae(predictions, verbose=True)\n",
    "#-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
